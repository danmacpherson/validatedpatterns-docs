---
title: Getting Started
weight: 10
aliases: /federated-edge-observability/getting-started/
---

:toc:
:imagesdir: /images
:_content-type: ASSEMBLY
include::modules/comm-attributes.adoc[]

[id="deploying-fe-pattern"]
== Deploying the {fe-pattern}

.Prerequisites

* An OpenShift cluster
 ** To create an OpenShift cluster, go to the https://console.redhat.com/[Red Hat Hybrid Cloud console].
 ** Select *OpenShift \-> Red Hat OpenShift Container Platform \-> Create cluster*.
* A GitHub account and a token for it with repositories permissions, to read from and write to your forks.
* The Helm binary, see link:https://helm.sh/docs/intro/install/[Installing Helm]
For installation tooling dependencies, see link:https://validatedpatterns.io/learn/quickstart/[Patterns quick start].

[id="preparing-for-deployment"]
== Preparing for deployment
.Procedure

. Fork the link:https://github.com/validatedpatterns-sandbox/federated-edge-observability[federated-edge-observability] repository on GitHub. You must fork the repository because your fork will be updated as part of the GitOps and DevOps processes.

. Clone the forked copy of this repository.
+
[source,terminal]
----
$ git clone git@github.com:<your-username>/federated-edge-observability.git
----

. Go to your repository: Ensure you are in the root directory of your Git repository by using:
+
[source,terminal]
----
$ cd /path/to/your/repository
----

. Run the following command to set the upstream repository:
+
[source,terminal]
----
$ git remote add -f upstream git@github.com:validatedpatterns-sandbox/federated-edge-observability.git
----

. Verify the setup of your remote repositories by running the following command:
+
[source,terminal]
----
$ git remote -v
----
+
.Example output
+
[source,terminal]
----
origin	git@github.com:kquinn1204/federated-edge-observability.git (fetch)
origin	git@github.com:kquinn1204/federated-edge-observability.git (push)
upstream	git@github.com:validatedpatterns-sandbox/federated-edge-observability.git (fetch)
upstream	git@github.com:validatedpatterns-sandbox/federated-edge-observability.git (push)
----

. Create a local copy of the Helm values file that can safely include credentials.
+
[WARNING]
====
Do not commit this file. You do not want to push personal credentials to GitHub.
====
+
Run the following commands:
+
[source,terminal]
----
$ cp values-secret.yaml.template ~/values-secret.yaml
----

. You want to populate this file with a number of secrets, or credentials, that will be needed to deploy the pattern successfully:
+
[source,terminal]
----
$ vi ~/values-secret.yaml
----

.. Edit the `vm-ssh` section to include the username, private key, and public key. For example: 
+
[source,yaml]
----
  - name: vm-ssh
    fields:
    - name: username
      value: 'cloud-user'
    - name: privatekey
      value: 'private ssh key'
    - name: publickey
      value: 'public ssh key'
----
+
Paste in an existing private key and public key, or generate a new key pair using the `ssh-keygen` command.

.. Edit the `rhsm` section to include the Red Hat Subscription Management username and password. For example:
+
[source,yaml]
----
  - name: rhsm
    fields:
    - name: username
      value: 'username of user to register RHEL VMs'
    - name: password
      value: 'password of rhsm user in plaintext'
----

.. Edit the `cloud-init` section to include the `userData` block to use with cloud-init. For example:
+
[source,yaml]
----
  - name: cloud-init
    fields:
    - name: userData
      value: |-
        #cloud-config
        user: 'cloud-user'
        password: 'cloud-user'
        chpasswd: { expire: False }

----

.. Edit the `aap-manifest` section to include the path to the downloaded manifest zip file that gives an entitlement to run Ansible Automation Platform. Create a subscription manifest by following the guidance at link:https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.4/html-single/red_hat_ansible_automation_platform_operations_guide/index#proc-create-subscription-allocation_obtain-manifest[Obtaining a manifest file]. For example add the following: 
+
[source,yaml]
----
  - name: aap-manifest
    fields:
    - name: '~/Downloads/<manifest_filename>.zip'
----

.. Edit the `automation-hub-token` section to include the token generated at . Click the *Load token* link at link:https://console.redhat.com/ansible/automation-hub/token[Automation Hub Token] to generate a token. For example:
+
[source,yaml]
----
  - name: automation-hub-token
    fields:
    - name: token
      value:
----

.. Optionally: Edit the `agof-vault-file` section to include the path to a valid `agof_vault` file for secrets to overlay the IaC config. For this pattern, use the following (you do not need additional secrets for this pattern):
+
[source,yaml]
----
  - name: agof-vault-file
    fields:
    - name: agof-vault-file
      path: '---'
      base64: true

----

.. Edit the `otel-cert` section to include the path to a pre-existing TLS key and certificate. Populate as shown below:
+
[source,yaml]
----
  - name: otel-cert
    fields:
    - name: tls.key
      path: '~/federated-edge-observability-otel-collector-edge-observability-stack.key'

    - name: tls.crt
      path: '~/federated-edge-observability-otel-collector-edge-observability-stack.crt'
----
+
Certificates for the OpenTelemetry collector infrastructure. "`Snakeoil`" (that is, self-signed) certs will automatically be generated by the makefile as follows by the `make snakeoil-certs` target, which is automatically run by `make install`.

. Create and switch to a new branch named my-branch, by running the following command:
+
[source,terminal]
----
$ git checkout -b my-branch
----

. Edit the `values-global.yaml` file to customize the deployment for your cluster. The defaults in `values-global.yaml` are designed to work in AWS. For example:
+
[source,terminal]
----
$ vi values-global.yaml
----

. Add the changes to the staging area by running the following command:
+
[source,terminal]
----
$ git add values-global.yaml
----

. Commit the changes by running the following command:
+
[source,terminal]
----
$ git commit -m "No updates"
----

. Push the changes to your forked repository:
+
[source,terminal]
----
$ git push origin my-branch
----

You can proceed to install the {fe-pattern} pattern by using the web console or from command line by using the script `./pattern.sh` script. 

To install the {fe-pattern} pattern by using the web console you must first install the Validated Patterns Operator. The Validated Patterns Operator installs and manages Validated Patterns. 

//Include Procedure module here
[id="installing-validated-patterns-operator_{context}"]
== Installing the {fe-pattern} using the web console

.Prerequisites
* Access to an {ocp} cluster by using an account with `cluster-admin` permissions.

.Procedure

. Navigate in the {hybrid-console-first} to the *Operators* → *OperatorHub* page.

. Scroll or type a keyword into the *Filter by keyword* box to find the Operator you want. For example, type `validated patterns` to find the {validated-patterns-op}.

. Select the Operator to display additional information.
+
[NOTE]
====
Choosing a Community Operator warns that Red Hat does not certify Community Operators; you must acknowledge the warning before continuing.
====

. Read the information about the Operator and click *Install*.

. On the *Install Operator* page:

.. Select an *Update channel* (if more than one is available).

.. Select a *Version* (if more than one is available).

.. Select an *Installation mode*:
+
The only supported mode for this Operator is *All namespaces on the cluster (default)*. This installs the Operator in the default `openshift-operators` namespace to watch and be made available to all namespaces in the cluster. This option is not always available.

.. Select *Automatic* or *Manual* approval strategy.

. Click *Install* to make the Operator available to the selected namespaces on this {ocp} cluster.

.Verification
To confirm that the installation is successful:

. Navigate to the *Operators* → *Installed Operators* page.

. Check that the Operator is installed in the selected namespace and its status is `Succeeded`.

//Include Procedure module here
[id="create-pattern-instance_{context}"]
== Creating the Medical Diagnosis GitOps instance

.Prerequisites
The {med-pattern} is successfully installed in the relevant namespace.

.Procedure

. Navigate to the *Operators* → *Installed Operators* page.

. Click the installed *{validated-patterns-op}*.

. Under the *Details* tab, in the *Provided APIs* section, in the
*Pattern* box, click *Create instance* that displays the *Create Pattern* page.

. On the *Create Pattern* page, select *Form view* and enter information in the following fields:

** *Name* - A name for the pattern deployment that is used in the projects that you created.
** *Labels* - Apply any other labels you might need for deploying this pattern.
** *Cluster Group Name* - Select a cluster group name to identify the type of cluster where this pattern is being deployed. For example, if you are deploying the {ie-pattern}, the cluster group name is `datacenter`. If you are deploying the {mcg-pattern}, the cluster group name is `hub`.
+
To know the cluster group name for the patterns that you want to deploy, check the relevant pattern-specific requirements.
. Expand the *Git Config* section to reveal the options and enter the required information.
. Leave *In Cluster Git Server* unchanged. 
.. Change the *Target Repo* URL to your forked repository URL. For example, change `+https://github.com/validatedpatterns/<pattern_name>+` to `+https://github.com/<your-git-username>/<pattern-name>+`
.. Optional: You might need to change the *Target Revision* field. The default value is `HEAD`. However, you can also provide a value for a branch, tag, or commit that you want to deploy. For example, `v2.1`, `main`, or a branch that you created, `my-branch`.
. Click *Create*.
+
[NOTE]
====
A pop-up error with the message "Oh no! Something went wrong." might appear during the process. This error can be safely disregarded as it does not impact the installation of the Multicloud GitOps pattern. Use the Hub ArgoCD UI, accessible through the nines menu, to check the status of ArgoCD instances, which will display states such as progressing, healthy, and so on, for each managed application. The Cluster ArgoCD provides detailed status on each application, as defined in the clustergroup values file.
====

The {rh-gitops} Operator displays in list of *Installed Operators*. The {rh-gitops} Operator installs the remaining assets and artifacts for this pattern. To view the installation of these assets and artifacts, such as {rh-rhacm-first}, ensure that you switch to *Project:All Projects*.

Wait some time for everything to deploy. You can track the progress through the `Hub ArgoCD` UI from the nines menu. The `xraylab-database` project  appears stuck in a `Degraded` state. This is the expected behavior when installing using the OpenShift Container Platform console.

* To resolve this you need to run the following to load the secrets into the vault:
+
[source,terminal]
----
$ ./pattern.sh make load-secrets
----
+
[NOTE]
====
You must have created a local copy of the secret values file by running the following command:

[source,terminal]
----
$ cp values-secret.yaml.template ~/values-secret-medical-diagnosis.yaml
----
====

The deployment will not take long but it should deploy successfully.

Alternatively you can deploy the {med-pattern} pattern by using the command line script `pattern.sh`. 

[id="deploying-cluster-using-patternsh-file"]
== Deploying the cluster by using the pattern.sh file

To deploy the cluster by using the `pattern.sh` file, complete the following steps:

. Log in to your cluster by running the following command:
+
[source,terminal]
----
$ oc login
----
+
Optional: Set the `KUBECONFIG` variable for the `kubeconfig` file path:
+
[source,terminal]
----
$ export KUBECONFIG=~/<path_to_kubeconfig>
----

. Deploy the pattern to your cluster. Run the following command:
+
[source,terminal]
----
$ ./pattern.sh make install
----

. Verify that the Operators have been installed.
 .. To verify, in the OpenShift Container Platform web console, navigate to *Operators → Installed Operators* page.
 .. Check that the *Red Hat OpenShift GitOps Operator* is installed in the `openshift-operators` namespace and its status is `Succeeded`.
. Wait some time for everything to deploy. You can track the progress through the `Hub ArgoCD` UI from the nines menu. 
+
image::../../images/medical-edge/medical-diags-overview.png[link="/images/medical-edge/medical-diags-overview.png"]

As part of installing by using the script `pattern.sh` pattern, HashiCorp Vault is installed. Running `./pattern.sh make install` also calls the `load-secrets` makefile target. This `load-secrets` target looks for a YAML file describing the secrets to be loaded into vault and in case it cannot find one it will use the `values-secret.yaml.template` file in the git repository to try to generate random secrets.

For more information, see section on https://validatedpatterns.io/secrets/vault/[Vault].

.Verification 

To check the various applications that are being deployed, you can view the progress of the {rh-gitops-short} Operator.

[IMPORTANT]
====
Examine the `medical-diagnosis-hub` ArgoCD instance. You can track all the applications for the pattern in this instance.
====

. Check that all applications are synchronized. There are thirteen different ArgoCD `applications` that are deployed as part of this pattern.

===============================================================================
== Credentials Required in Pattern

In addition to the openshift cluster, you will need to prepare a number of secrets, or credentials, which will be used in the pattern in various
ways. To do this, copy the https://github.com/validatedpatterns-sandbox/federated-edge-observability/blob/main/values-secret.yaml.template[values-secret.yaml
template] to your home directory as `+values-secret.yaml+` and replace
the explanatory text as follows:


[source,yaml]
----
---
# NEVER COMMIT THESE VALUES TO GIT
version: "2.0"
secrets:
----

* A username and SSH Keypair (private key and public key). These will be
used to provide access to the Kiosk VMs in the demo.

[source,yaml]
----
  - name: vm-ssh
    fields:
    - name: username
      value: 'Username of user to attach privatekey and publickey to - cloud-user is a typical value'

    - name: privatekey
      value: 'Private ssh key of the user who will be able to elevate to root to provision kiosks'

    - name: publickey
      value: 'Public ssh key of the user who will be able to elevate to root to provision kiosks'
----

* A Red Hat Subscription Management username and password. These will be
used to register Kiosk VM templates to the Red Hat Content Delivery
Network and install content on the VMs and to install the Otel
collector.

[source,yaml]
----
  - name: rhsm
    fields:
    - name: username
      value: 'username of user to register RHEL VMs'
    - name: password
      value: 'password of rhsm user in plaintext'
----

* A userData block to use with cloud-init. This will allow console login
as the user you specify (traditionally cloud-user) with the password you
specify. The value in cloud-init is used as the default; roles in the
edge-gitops-vms chart can also specify other secrets to use by
referencing them in the role block.

[source,yaml]
----
  - name: cloud-init
    fields:
    - name: userData
      value: |-
        #cloud-config
        user: 'username of user for console, probably cloud-user'
        password: 'a suitable password to use on the console'
        chpasswd: { expire: False }
----

* A manifest file with an entitlement to run Ansible Automation
Platform. This file (which will be a .zip file) will be posted to to
Ansible Automation Platform instance to enable its use. Instructions for
creating a manifest file can be found
https://www.redhat.com/en/blog/how-create-and-use-red-hat-satellite-manifest[here]

[source,yaml]
----
  - name: aap-manifest
    fields:
    - name: b64content
      path: 'full pathname of file containing Satellite Manifest for entitling Ansible Automation Platform'
      base64: true
----

[source,yaml]
----
- name: automation-hub-token
    fields:
    - name: token
      value: 'An automation hub token for retrieving Certified and Validated Ansible content'
----

* An automation hub token generated at
https://console.redhat.com/ansible/automation-hub/token. This is needed
for the Ansible Configuration-as-Code tools.

[source,yaml]
----
  - name: agof-vault-file
    fields:
    - name: agof-vault-file
      path: 'full pathname of a valid agof_vault file for secrets to overlay the iac config'
      base64: true
----

* An (optional) AGOF vault file. For this pattern, use the following
(you do not need additional secrets for this pattern):

[source,yaml]
----
- name: agof-vault-file
  fields:
    - name: agof-vault-file
      value: '---'
      base64: true
----

[source,yaml]
----
  - name: otel-cert
    fields:
    - name: tls.key
      path: 'full pathname to a pre-existing tls key'

    - name: tls.crt
      path: 'full pathname to a pre-existing tls certificate'
----

Certificates for the open telemetry collector infrastructure.
"`Snakeoil`" (that is, self-signed) certs will automatically be
generated by the makefile as follows by the `+make snakeoil-certs+`
target, which is automatically run by `+make install+`:

[source,yaml]
----
- name: otel-cert
  fields:
    - name: tls.key
      path: ~/federated-edge-observability-otel-collector-edge-observability-stack.key

    - name: tls.crt
      path: ~/federated-edge-observability-otel-collector-edge-observability-stack.crt
----

== How to deploy

[arabic]
. Login to your cluster using oc login or exporting the KUBECONFIG
+
[source,sh]
----
oc login
----
+
or set KUBECONFIG to the path to your `+kubeconfig+` file. For example:
+
[source,sh]
----
export KUBECONFIG=~/my-ocp-env/hub/auth/kubeconfig
----
. Fork the
https://github.com/validatedpatterns-sandbox/federated-edge-observability[federated-edge-observability]
repo on GitHub. It is necessary to fork to preserve customizations you
make to the default configuration files.
. Clone the forked copy of this repository.
+
[source,sh]
----
git clone git@github.com:your-username/ansible-edge-gitops.git
----
. Create a local copy of the Helm values file that can safely include
credentials
+
WARNING: DO NOT COMMIT THIS FILE
+
You do not want to push personal credentials to GitHub.
+
[source,sh]
----
cp values-secret.yaml.template ~/values-secret.yaml
vi ~/values-secret.yaml
----
. Customize the deployment for your cluster (Optional - the defaults in
values-global.yaml are designed to work in AWS):
+
[source,sh]
----
git checkout -b my-branch
vi values-global.yaml
git add values-global.yaml
git commit values-global.yaml
git push origin my-branch
----

Please review the link:/learn/quickstart/[Patterns quick start] page.
This section describes deploying the pattern using `+pattern.sh+`. You
can deploy the pattern using the
link:/infrastructure/using-validated-pattern-operator/[validated pattern
operator]. If you do use the operator then skip to Validating the
Environment below.

[arabic]
. (Optional) Preview the changes. If you’d like to review what is been
deployed with the pattern, `+pattern.sh+` provides a way to show what
will be deployed.
+
[source,sh]
----
./pattern.sh make show
----
. Apply the changes to your cluster. This will install the pattern via
the Validated Patterns Operator, and then run any necessary follow-up
steps.
+
[source,sh]
----
./pattern.sh make install
----

The installation process will take between 45-60 minutes to complete.

== Installation Validation

* Check the operators have been installed using the OpenShift console
+
[source,text]
----
OpenShift Console Web UI -> Installed Operators
----

.federated-edge-observability-operators
image::/images/federated-edge-observability/FEO-operators.png[federated-edge-observability-operators,title="Federated Edge Observability Operators"]

* Check all applications are synchronised

Under the project `+federated-edge-observability-hub+` click on the URL
for the `+hub+`gitops`+server+`. All applications will sync, but this
takes time as ODF has to completely install, and OpenShift
Virtualization cannot provision VMs until the metal node has been fully
provisioned and ready.

.federated-edge-observability-applications
image::/images/federated-edge-observability/FEO-applications.png[federated-edge-observability-applications,title="Federated Edge Observability Applications"]

* Under Virtualization > Virtual Machines, the virtual machines will
eventually show as "`Running.`" Once they are in "`Running`" state the
Provisioning workflow will run on them, install the OpenTelemetry
collector, and start reporting metrics to the Edge Observability Stack
in the hub cluster.

.federated-edge-observability-vms
image::/images/federated-edge-observability/FEO-vms.png[federated-edge-observability-vms,title="Federated Edge Observability Virtual Machines"]

* The Grafana graphs should be receiving data and drawing graphs for
each of the nodes:

.federated-edge-observability-grafana
image::/images/federated-edge-observability/FEO-grafana.png[federated-edge-observability-grafana,title="Federated Edge Observability Graphs"]

Please see
link:/federated-edge-observability/ansible-automation-platform/[Ansible
Automation Platform] for more information on how this pattern uses the
Ansible Automation Platform Operator for OpenShift.

== Infrastructure Elements of this Pattern

=== https://www.redhat.com/en/technologies/management/ansible[Ansible Automation Platform]

A fully functional installation of the Ansible Automation Platform
operator is installed on your OpenShift cluster to configure and
maintain the VMs for this demo. AAP maintains a dynamic inventory of
kiosk machines and can configure a VM from template to fully functional
kiosk in about 10 minutes.

=== OpenShift https://docs.openshift.com/container-platform/4.16/virt/about_virt/about-virt.html[Virtualization]

OpenShift Virtualization is a Kubernetes-native way to run virtual
machine workloads. It is used in this pattern to host VMs simulating an
Edge environment; the chart that configures the VMs is designed to be
flexible to allow easy customization to model different VM sizes, mixes,
versions and profiles for future pattern development.

=== HashiCorp https://www.vaultproject.io/[Vault]

Vault is used as the authoritative source for the Kiosk ssh pubkey via
the External Secrets Operator. As part of this pattern HashiCorp Vault
has been installed. Refer to the section on
https://validatedpatterns.io/secrets/vault/[Vault].

== Next Steps

=== https://groups.google.com/g/validatedpatterns[Help & Feedback]

=== https://github.com/validatedpatterns-sandbox/federated-edge-observability/issues[Report Bugs]
